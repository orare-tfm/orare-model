{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing RAG with Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "https://github.com/openai/openai-cookbook/blob/main/examples/vector_databases/pinecone/Using_Pinecone_for_embeddings_search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "from typing import List, Iterator\n",
    "\n",
    "# Function to set the wd as the root of the repository\n",
    "def find_repo_root(repo_name):\n",
    "    current_dir = os.getcwd()\n",
    "    while current_dir != '/':\n",
    "        if os.path.basename(current_dir) == repo_name:\n",
    "            return current_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    raise FileNotFoundError(f\"Repository root '{repo_name}' not found.\")\n",
    "\n",
    "# Setting the working directory\n",
    "repo_name = 'orare-model'\n",
    "repo_root = find_repo_root(repo_name)\n",
    "os.chdir(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore unclosed SSL socket warnings - optional in case you get these errors\n",
    "#import warnings\n",
    "\n",
    "#warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ResourceWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 861 entries, 0 to 860\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     861 non-null    object\n",
      " 1   pasaje                 861 non-null    object\n",
      " 2   texto                  861 non-null    object\n",
      " 3   interpretación         861 non-null    object\n",
      " 4   temas                  861 non-null    object\n",
      " 5   área_vida              861 non-null    object\n",
      " 6   texto_vector           861 non-null    object\n",
      " 7   interpretacion_vector  861 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 53.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the bible interpreted with embeddings\n",
    "bible_data = pd.read_csv('bible/data/bible_by_theme_int_embedding.txt', sep='|', encoding='utf-8')\n",
    "\n",
    "# Tranforming vector string into list\n",
    "bible_data['interpretacion_vector'] = bible_data['interpretacion_vector'].apply(ast.literal_eval)\n",
    "\n",
    "# Showing the bible_data object\n",
    "bible_data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the connection to OpenAI API and Pinecone API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroshi/Documents/ds_projects/orare-model/venv/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "# Pinecone's client library for Python\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Pinecone API\n",
    "pc_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "\n",
    "# OpenAI API\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models a simple batch generator that make chunks out of an input DataFrame\n",
    "class BatchGenerator:\n",
    "   \n",
    "    def __init__(self, batch_size: int = 10) -> None:\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    # Makes chunks out of an input DataFrame\n",
    "    def to_batches(self, df: pd.DataFrame) -> Iterator[pd.DataFrame]:\n",
    "        splits = self.splits_num(df.shape[0])\n",
    "        if splits <= 1:\n",
    "            yield df\n",
    "        else:\n",
    "            for chunk in np.array_split(df, splits):\n",
    "                yield chunk\n",
    "\n",
    "    # Determines how many chunks DataFrame contains\n",
    "    def splits_num(self, elements: int) -> int:\n",
    "        return round(elements / self.batch_size)\n",
    "    \n",
    "    __call__ = to_batches\n",
    "\n",
    "df_batcher = BatchGenerator(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'bible-verses' already exists. Deleting it.\n"
     ]
    }
   ],
   "source": [
    "index_name = 'bible-verses'\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    print(f\"Index '{index_name}' already exists. Deleting it.\")\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "if index_name in pc.list_indexes():\n",
    "    pc.delete_index(index_name)\n",
    "    \n",
    "# Create new index with the required 'spec' argument\n",
    "spec = ServerlessSpec(\n",
    "    cloud='aws',\n",
    "    region='us-east-1'\n",
    ")\n",
    "\n",
    "# Getting the embedding vector length\n",
    "vector_length = len(bible_data['interpretacion_vector'][0])\n",
    "# Creates new index\n",
    "pc.create_index(name=index_name, dimension=vector_length, spec=spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'deletion_protection': 'disabled',\n",
       "              'dimension': 1536,\n",
       "              'host': 'orare-app-rsup9mo.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'orare-app',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}},\n",
       "             {'deletion_protection': 'disabled',\n",
       "              'dimension': 1536,\n",
       "              'host': 'bible-verses-rsup9mo.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'bible-verses',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'bible-verses'\n",
    "# Setting the host of the index from the Pinecone web admin portal\n",
    "index = pc.Index(index_name=index_name, host='https://bible-verses-rsup9mo.svc.aped-4627-b74a.pinecone.io')\n",
    "\n",
    "# Confirm our index was created\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the vectors to the content namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading vectors to content namespace..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroshi/Documents/ds_projects/orare-model/venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Upsert content vectors in content namespace - this can take a few minutes\n",
    "print(\"Uploading vectors to content namespace..\")\n",
    "for batch_df in df_batcher(bible_data):\n",
    "    index.upsert(vectors=zip(batch_df.id, batch_df.interpretacion_vector), namespace='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'content': {'vector_count': 861}},\n",
       " 'total_vector_count': 861}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index size for each namespace to confirm all of our docs have loaded\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionaries mapping vector IDs to their outputs so we can retrieve the text for our search results\n",
    "titles_mapped = dict(zip(bible_data.id,bible_data.pasaje))\n",
    "content_mapped = dict(zip(bible_data.id,bible_data.interpretación))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the embedding model of OpenAI\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# Function to query the vector search\n",
    "def query_article(query, namespace, top_k=3):\n",
    "\n",
    "    # Function to get the embeddings of the input of the search\n",
    "    def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "       text = text.replace(\"\\n\", \" \")\n",
    "       return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    \n",
    "    embedded_query = get_embedding(query,model=EMBEDDING_MODEL)\n",
    "\n",
    "    # Query namespace passed as parameter using title vector\n",
    "    query_result = index.query(vector=embedded_query, \n",
    "                               top_k=top_k,\n",
    "                               namespace=namespace)\n",
    "\n",
    "    # Print query results \n",
    "    print(f'\\nMost similar results to {query} in \"{namespace}\" namespace:\\n')\n",
    "    if not query_result.matches:\n",
    "        print('no query result')\n",
    "    \n",
    "    matches = query_result.matches\n",
    "    ids = [res.id for res in matches]\n",
    "    scores = [res.score for res in matches]\n",
    "    df = pd.DataFrame({'id':ids, \n",
    "                       'score':scores,\n",
    "                       'title': [titles_mapped[_id] for _id in ids],\n",
    "                       'content': [content_mapped[_id] for _id in ids],\n",
    "                       })\n",
    "    \n",
    "    counter = 0\n",
    "    for k,v in df.iterrows():\n",
    "        counter += 1\n",
    "        print(f'{v.title}: {v.content} (score = {v.score})')\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar results to Dios. Quiero que en este proceso de búsqueda seas mi fuerza y me acompañes en todo momento. \n",
      "Yo se que tienes para mi un plan. Yo se que tu siempre das en la medida correcta y que poco a poco me has mostrado el camino para mi crecimiento.\n",
      "Hace un tiempo me faltaba confianza en mi mismo. Se que con la experiencia laboral anterior me diste la oportunidad de abrir los ojos y saber quien soy.\n",
      "Te doy las gracias porque se que cada paso que me muestras es un paso hacia desarrollar mi máximo potencial.\n",
      " in \"content\" namespace:\n",
      "\n",
      "Proverbios 3:5, 6: Este pasaje nos enseña a confiar plenamente en Dios y no depender únicamente de nuestra propia sabiduría o entendimiento. Al reconocer a Dios en todas nuestras acciones y decisiones, Él guiará y corregirá nuestro camino. (score = 0.551148355)\n",
      "Job 11:18, 19: Este pasaje habla de la confianza en Dios y la esperanza que trae seguridad y paz. Se menciona que, al confiar en Dios, uno puede descansar sin temor y que otros buscarán tu favor. (score = 0.536897242)\n",
      "Jeremías 29:11-13: Dios asegura a su pueblo que tiene planes de bienestar y no de mal para ellos, prometiendo un futuro esperanzador. Les invita a buscarlo sinceramente a través de la oración, asegurándoles que los escuchará y se dejará encontrar. (score = 0.516509175)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''Dios. Quiero que en este proceso de búsqueda seas mi fuerza y me acompañes en todo momento. \n",
    "Yo se que tienes para mi un plan. Yo se que tu siempre das en la medida correcta y que poco a poco me has mostrado el camino para mi crecimiento.\n",
    "Hace un tiempo me faltaba confianza en mi mismo. Se que con la experiencia laboral anterior me diste la oportunidad de abrir los ojos y saber quien soy.\n",
    "Te doy las gracias porque se que cada paso que me muestras es un paso hacia desarrollar mi máximo potencial.\n",
    "'''\n",
    "query_output = query_article(query=query,namespace='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
