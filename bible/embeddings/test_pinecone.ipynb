{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing RAG with Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "https://github.com/openai/openai-cookbook/blob/main/examples/vector_databases/pinecone/Using_Pinecone_for_embeddings_search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Vector Database in Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "from typing import List, Iterator\n",
    "\n",
    "# Function to set the wd as the root of the repository\n",
    "def find_repo_root(repo_name):\n",
    "    current_dir = os.getcwd()\n",
    "    while current_dir != '/':\n",
    "        if os.path.basename(current_dir) == repo_name:\n",
    "            return current_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    raise FileNotFoundError(f\"Repository root '{repo_name}' not found.\")\n",
    "\n",
    "# Setting the working directory\n",
    "repo_name = 'orare-model'\n",
    "repo_root = find_repo_root(repo_name)\n",
    "os.chdir(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 861 entries, 0 to 860\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     861 non-null    object\n",
      " 1   pasaje                 861 non-null    object\n",
      " 2   texto                  861 non-null    object\n",
      " 3   interpretación         861 non-null    object\n",
      " 4   temas                  861 non-null    object\n",
      " 5   área_vida              861 non-null    object\n",
      " 6   texto_vector           861 non-null    object\n",
      " 7   interpretacion_vector  861 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 53.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the bible interpreted with embeddings\n",
    "bible_data = pd.read_csv('bible/data/bible_by_theme_int_embedding.txt', sep='|', encoding='utf-8')\n",
    "\n",
    "# Tranforming vector string into list\n",
    "bible_data['interpretacion_vector'] = bible_data['interpretacion_vector'].apply(ast.literal_eval)\n",
    "\n",
    "# Showing the bible_data object\n",
    "bible_data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>interpretacion_vector</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.05086807906627655, 0.006340509746223688, 0....</td>\n",
       "      <td>{'pasaje': '1 Corintios 10:12', 'texto': 'Así ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.04511460289359093, -0.013647807762026787, -...</td>\n",
       "      <td>{'pasaje': '1 Corintios 10:13', 'texto': 'No o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0449271984398365, 0.04290250688791275, -0.0...</td>\n",
       "      <td>{'pasaje': '1 Corintios 10:31', 'texto': 'Si p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.06745994836091995, 0.06209307909011841, -0....</td>\n",
       "      <td>{'pasaje': '1 Corintios 11:9', 'texto': 'Porqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.030204113572835922, -0.004405524581670761, ...</td>\n",
       "      <td>{'pasaje': '1 Corintios 13:13', 'texto': 'Y ah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              interpretacion_vector  \\\n",
       "0   1  [0.05086807906627655, 0.006340509746223688, 0....   \n",
       "1   2  [0.04511460289359093, -0.013647807762026787, -...   \n",
       "2   3  [0.0449271984398365, 0.04290250688791275, -0.0...   \n",
       "3   4  [0.06745994836091995, 0.06209307909011841, -0....   \n",
       "4   5  [0.030204113572835922, -0.004405524581670761, ...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'pasaje': '1 Corintios 10:12', 'texto': 'Así ...  \n",
       "1  {'pasaje': '1 Corintios 10:13', 'texto': 'No o...  \n",
       "2  {'pasaje': '1 Corintios 10:31', 'texto': 'Si p...  \n",
       "3  {'pasaje': '1 Corintios 11:9', 'texto': 'Porqu...  \n",
       "4  {'pasaje': '1 Corintios 13:13', 'texto': 'Y ah...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatting the Bible dataframe\n",
    "# Transforming index as numeric value\n",
    "bible_data['id'] = bible_data['id'].str.replace('vec', '').astype(int)\n",
    "\n",
    "# Craeting column \"metadata\"\n",
    "bible_data['metadata'] = bible_data.apply(lambda row: {\n",
    "    'pasaje': row['pasaje'],\n",
    "    'texto': row['texto'],\n",
    "    'interpretacion': row['interpretación'],\n",
    "    'temas': row['temas'],\n",
    "    'area_vida': row['área_vida']\n",
    "}, axis=1)\n",
    "\n",
    "# Dropping the columns inserted in metadata\n",
    "bible_data = bible_data.drop(columns=['pasaje','texto','interpretación','temas','área_vida'])\n",
    "\n",
    "# Reordering columns\n",
    "columns = ['id','interpretacion_vector','metadata']\n",
    "bible_data = bible_data[columns]\n",
    "bible_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the connection to OpenAI API and Pinecone API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroshi/Documents/ds_projects/orare-model/venv/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Pinecone API\n",
    "pc_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "\n",
    "# OpenAI API\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models a simple batch generator that make chunks out of an input DataFrame\n",
    "class BatchGenerator:\n",
    "   \n",
    "    def __init__(self, batch_size: int = 10) -> None:\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    # Makes chunks out of an input DataFrame\n",
    "    def to_batches(self, df: pd.DataFrame) -> Iterator[pd.DataFrame]:\n",
    "        splits = self.splits_num(df.shape[0])\n",
    "        if splits <= 1:\n",
    "            yield df\n",
    "        else:\n",
    "            for chunk in np.array_split(df, splits):\n",
    "                yield chunk\n",
    "\n",
    "    # Determines how many chunks DataFrame contains\n",
    "    def splits_num(self, elements: int) -> int:\n",
    "        return int(np.ceil(elements / self.batch_size))\n",
    "    \n",
    "    __call__ = to_batches\n",
    "\n",
    "df_batcher = BatchGenerator(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Index in the Pinecone webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'content': {'vector_count': 861}},\n",
       " 'total_vector_count': 861}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'bible-verses-metadata'\n",
    "\n",
    "# Setting the host of the index from the Pinecone web admin portal\n",
    "index = pc.Index(index_name=index_name, host='https://bible-verses-metadata-rsup9mo.svc.aped-4627-b74a.pinecone.io')\n",
    "\n",
    "# Confirm our index was created\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the vectors to the content namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading vectors to content namespace..\n"
     ]
    }
   ],
   "source": [
    "# Upsert content vectors in content namespace - this can take a few minutes\n",
    "print(\"Uploading vectors to content namespace..\")\n",
    "for batch_df in df_batcher(bible_data):\n",
    "    vectors = list(zip(batch_df.id.astype(str), batch_df.interpretacion_vector, batch_df.metadata))\n",
    "    index.upsert(vectors=vectors, namespace='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'content': {'vector_count': 861}},\n",
       " 'total_vector_count': 861}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index size for each namespace to confirm all of our docs have loaded\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries and setting the clients\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "# Pinecone's client library for Python\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Pinecone API\n",
    "pc_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pc_api_key)\n",
    "\n",
    "# OpenAI API\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the embedding model of OpenAI\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# Function to query the vector search\n",
    "def query_article(query, namespace, top_k=3):\n",
    "\n",
    "    # Function to get the embeddings of the input of the search\n",
    "    def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "       text = text.replace(\"\\n\", \" \")\n",
    "       return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    \n",
    "    embedded_query = get_embedding(query,model=EMBEDDING_MODEL)\n",
    "\n",
    "    # Query namespace passed as parameter using title vector\n",
    "    query_result = index.query(vector=embedded_query, \n",
    "                               top_k=top_k,\n",
    "                               namespace=namespace,\n",
    "                               include_metadata=True)\n",
    "\n",
    "    # Print query results \n",
    "    print(f\"Oración: {query}\")\n",
    "    print('\\n')\n",
    "    for match in query_result['matches']:\n",
    "        print(f\"id: {match.id}, score: {match.score}\")\n",
    "        print(f\"pasaje: {match.metadata['pasaje']}\")\n",
    "        print(f\"texto: {match.metadata['texto']}\")\n",
    "        print(f\"pasaje: {match.metadata['interpretacion']}\")\n",
    "        print('\\n')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración: Dios. Quiero que en este proceso de búsqueda seas mi fuerza y me acompañes en todo momento. \n",
      "Yo se que tienes para mi un plan. Yo se que tu siempre das en la medida correcta y que poco a poco me has mostrado el camino para mi crecimiento.\n",
      "Hace un tiempo me faltaba confianza en mi mismo. Se que con la experiencia laboral anterior me diste la oportunidad de abrir los ojos y saber quien soy.\n",
      "Te doy las gracias porque se que cada paso que me muestras es un paso hacia desarrollar mi máximo potencial.\n",
      "\n",
      "id: 624, score: 0.551148355\n",
      "pasaje: Proverbios 3:5, 6\n",
      "texto: Fíate de Jehová de todo tu corazón, Y no estribes en tu prudencia. Reconócelo en todos tus caminos, Y él enderezará tus veredas.\n",
      "pasaje: Este pasaje nos enseña a confiar plenamente en Dios y no depender únicamente de nuestra propia sabiduría o entendimiento. Al reconocer a Dios en todas nuestras acciones y decisiones, Él guiará y corregirá nuestro camino.\n",
      "\n",
      "\n",
      "id: 388, score: 0.536897242\n",
      "pasaje: Job 11:18, 19\n",
      "texto: Y confiarás, que habrá esperanza; Y cavarás, y dormirás seguro: Y te acostarás, y no habrá quien te espante: Y muchos te rogarán.\n",
      "pasaje: Este pasaje habla de la confianza en Dios y la esperanza que trae seguridad y paz. Se menciona que, al confiar en Dios, uno puede descansar sin temor y que otros buscarán tu favor.\n",
      "\n",
      "\n",
      "id: 379, score: 0.516509175\n",
      "pasaje: Jeremías 29:11-13\n",
      "texto: Porque yo sé los pensamientos que tengo acerca de vosotros, dice Jehová, pensamientos de paz, y no de mal, para daros el fin que esperáis. Entonces me invocaréis, é iréis y oraréis á mí, y yo os oiré: Y me buscaréis y hallaréis, porque me buscaréis de todo vuestro corazón.\n",
      "pasaje: Dios asegura a su pueblo que tiene planes de bienestar y no de mal para ellos, prometiendo un futuro esperanzador. Les invita a buscarlo sinceramente a través de la oración, asegurándoles que los escuchará y se dejará encontrar.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prayer = '''Dios. Quiero que en este proceso de búsqueda seas mi fuerza y me acompañes en todo momento. \n",
    "Yo se que tienes para mi un plan. Yo se que tu siempre das en la medida correcta y que poco a poco me has mostrado el camino para mi crecimiento.\n",
    "Hace un tiempo me faltaba confianza en mi mismo. Se que con la experiencia laboral anterior me diste la oportunidad de abrir los ojos y saber quien soy.\n",
    "Te doy las gracias porque se que cada paso que me muestras es un paso hacia desarrollar mi máximo potencial.\n",
    "'''\n",
    "query_output = query_article(query=prayer,namespace='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración: Ilumíname señor, dame paz en estos momentos de incertidumbre, sujétame de tu mano, permíteme caminar junto a ti.\n",
      "¿Por qué permites este dolor dentro de nosotros? ¿Por qué este sufrimiento tan profundo? No lograré entender tus motivos, \n",
      "pero entiendo espiritualmente lo que estás haciendo conmigo.\n",
      "Purificas mi alma, me permitiste soltar el control, afianzarme a ti, volver a mirarte cara a cara, \n",
      "entender que todo depende de ti, reconocer la vanidad de mis actos, sentir miedo a cada instante y que mi única fuerza seas tú.\n",
      "No entiendo tus caminos pero decido caminar dentro de ellos, seguir tu luz, guiar a mi familia hacia tus designios, \n",
      "respirar en esa absoluta incertidumbre y orar con todas mis fuerzas para que se haga según tu voluntad.\n",
      "Cuida a mi familia señor, bendice a mi esposa, cúbrela con tu manto sagrado, fortalece a mi hijo, \n",
      "aliéntalo con tu espíritu, dale el soporte que hoy nosotros no podemos darle, \n",
      "que su angel guardián le cuente que estamos todos pendientes de él, \n",
      "que no contamos los minutos para tenerlo en nuestros brazos, pero que sea paciente,\n",
      "que tú tienes varios corazones que limpiar en estos momentos, que su venida está generando santidad en nuestro alrededor.\n",
      "\n",
      "\n",
      "id: 96, score: 0.544657648\n",
      "pasaje: 2 Colosenses 3:5\n",
      "texto: Y el Señor enderece vuestros corazones en el amor de Dios, y en la paciencia de Cristo.\n",
      "pasaje: Este versículo es una oración para que el Señor guíe y fortalezca los corazones de los creyentes en el amor de Dios y en la paciencia que Cristo mostró. Se trata de una petición para que los fieles puedan vivir de acuerdo con estos valores.\n",
      "\n",
      "\n",
      "id: 127, score: 0.536423802\n",
      "pasaje: 2 Samuel 22:5-7\n",
      "texto: Cuando me cercaron ondas de muerte, Y arroyos de iniquidad me asombraron, Me rodearon los dolores del infierno, Y me tomaron descuidado lazos de muerte. Tuve angustia, invoqué á Jehová, Y clamé á mi Dios: Y él oyó mi voz desde su templo; Llegó mi clamor á sus oídos.\n",
      "pasaje: El fragmento describe una situación de gran angustia y peligro, donde el autor se siente rodeado por la muerte y el mal. En su desesperación, clama a Dios, quien escucha su súplica y responde. Este pasaje resalta la importancia de la fe y la confianza en Dios en momentos de crisis.\n",
      "\n",
      "\n",
      "id: 725, score: 0.534591794\n",
      "pasaje: Salmos 142:3\n",
      "texto: Cuando mi espíritu se angustiaba dentro de mí, tú conociste mi senda. En el camino en que andaba, me escondieron lazo.\n",
      "pasaje: El salmista expresa su angustia y cómo Dios conoce su camino y las trampas que otros han puesto en su vida. Es un clamor de ayuda y confianza en la guía divina.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prayer = '''Ilumíname señor, dame paz en estos momentos de incertidumbre, sujétame de tu mano, permíteme caminar junto a ti.\n",
    "¿Por qué permites este dolor dentro de nosotros? ¿Por qué este sufrimiento tan profundo? No lograré entender tus motivos, \n",
    "pero entiendo espiritualmente lo que estás haciendo conmigo.\n",
    "Purificas mi alma, me permitiste soltar el control, afianzarme a ti, volver a mirarte cara a cara, \n",
    "entender que todo depende de ti, reconocer la vanidad de mis actos, sentir miedo a cada instante y que mi única fuerza seas tú.\n",
    "No entiendo tus caminos pero decido caminar dentro de ellos, seguir tu luz, guiar a mi familia hacia tus designios, \n",
    "respirar en esa absoluta incertidumbre y orar con todas mis fuerzas para que se haga según tu voluntad.\n",
    "Cuida a mi familia señor, bendice a mi esposa, cúbrela con tu manto sagrado, fortalece a mi hijo, \n",
    "aliéntalo con tu espíritu, dale el soporte que hoy nosotros no podemos darle, \n",
    "que su angel guardián le cuente que estamos todos pendientes de él, \n",
    "que no contamos los minutos para tenerlo en nuestros brazos, pero que sea paciente,\n",
    "que tú tienes varios corazones que limpiar en estos momentos, que su venida está generando santidad en nuestro alrededor.'''\n",
    "\n",
    "query_output = query_article(query=prayer,namespace='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
