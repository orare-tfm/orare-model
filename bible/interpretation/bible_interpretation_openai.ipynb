{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bible by Theme Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bible by Theme Interpretation: v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.os_utils import find_repo_root\n",
    "\n",
    "# Setting directory\n",
    "repo_root = find_repo_root()\n",
    "os.chdir(repo_root)\n",
    "\n",
    "# Loading Fragments of the Bible\n",
    "with open('bible/data/bible_by_theme_preprocessed.json') as f:\n",
    "    fragments = json.load(f)\n",
    "\n",
    "# Loading json in df\n",
    "fragments_df = pd.DataFrame(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion_4o(prompt, model=\"gpt-4o\"):\n",
    "    messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "       ]    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Instruction: v1\n",
    "instructions = \"\"\"\n",
    "# Rol #\n",
    "Tu eres el GPT: Catholic Bible Guide by Fr. Abraham Mutholath.\n",
    "Tu rol será el de un sacerdote de una iglesia Católica. Se te dará distintos fragmentos de la Biblia. Tu tarea será leer los fragmentos y realizar las tareas que se detallen en la siguiente sección.\n",
    "# Fin Rol #\n",
    "\n",
    "# Tareas #\n",
    "- Explicar la Biblia (explicacion): si el fragmento de la Biblia no está escrito en un lenguaje antiguo, es ambiguo o no está claro lo que quiere decir debes hacer una explicación breve y concisa. Solo explica lo que no es tan evidente y esté en un lenguaje antiguo o ambiguo.\n",
    "- Identificar Area de la vida (areas): de cada fragmento debes identificar el área de la vida de la que se habla. Las áreas de la vida pueden ser: Relaciones familiares/pareja, Amistad, Salud física, Salud mental/emocional, Desarrollo/crecimiento personal, Misión de vida, Dinero, Trabajo, Diversión/Hobbies, Otros.\n",
    "\n",
    "Para cada fragmento menciona entre 1 y 3 áreas que sean las más importantes.\n",
    "# fin Tareas #\n",
    "\n",
    "# Estructura input #\n",
    "\"id_libro|fragmento\"\n",
    "# Fin estructura input #\n",
    "\n",
    "# Estructura Output #\n",
    "El output debe ser un texto plano separado por | sin \"header\" ni \"footer\"\n",
    "id_libro|explicacion|areas(separado por comas)\n",
    "# Fin Estructura Output #\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_response = []\n",
    "\n",
    "for _, verse in fragments_df.iterrows():\n",
    "    input_to_interpret = f\"{verse['pasaje']}|{verse['texto']}\"\n",
    "    prompt = f\"\"\"\n",
    "                {instructions}\n",
    "\n",
    "                # Input # \n",
    "                {input_to_interpret}\n",
    "                # Fin Input #\n",
    "                \"\"\"\n",
    "    response_4o = get_completion_4o(prompt)\n",
    "    list_response.append(response_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_purpose = fragments_df['area_vida'].tolist()\n",
    "list_text = fragments_df['texto'].tolist()\n",
    "list_passage = fragments_df['pasaje'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_text(text):\n",
    "    flattened_text = text.replace('\\n', ' ')\n",
    "    flattened_text = ' '.join(flattened_text.split())\n",
    "    return flattened_text\n",
    "\n",
    "list_response2 = [flatten_text(response) for response in list_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting ChatGPT response into passage, interpretatino and areas\n",
    "list_passage_2 = []\n",
    "list_interpretation = []\n",
    "list_areas = []\n",
    "list_id = []\n",
    "\n",
    "i = 0\n",
    "for item in list_response2:\n",
    "    passage, interpretation = item.split('|')\n",
    "    i=i+1\n",
    "    id = \"vec\"+str(i)\n",
    "    list_id.append(id)\n",
    "    list_passage_2.append(passage)\n",
    "    list_interpretation.append(interpretation)\n",
    "    #list_areas.append(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the list_areas to store them as a list and not as a joined string\n",
    "# Also trim the white spaces\n",
    "list_areas_split = [[area.strip() for area in areas.split(',')] for areas in list_areas]\n",
    "print(list_areas_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating df with results\n",
    "bible_by_theme_interpreted = pd.DataFrame({\"id\": list_id,\n",
    "                                           \"pasaje\": list_passage,\n",
    "                                           \"texto\": list_text,\n",
    "                                           \"interpretación\": list_interpretation,\n",
    "                                           \"temas\": list_purpose,\n",
    "                                           \"área_vida\": list_areas_split})\n",
    "\n",
    "# Convert DataFrame to a dictionary\n",
    "bible_by_theme_interpreted_json = bible_by_theme_interpreted.to_dict(orient='records')\n",
    "\n",
    "# Save the list as a JSON file\n",
    "with open('bible/data/bible_by_theme_int_v1.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(bible_by_theme_interpreted_json, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bible by Theme Interpretation: v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.os_utils import find_repo_root\n",
    "\n",
    "# Setting directory\n",
    "repo_root = find_repo_root()\n",
    "os.chdir(repo_root)\n",
    "\n",
    "# Loading Fragments of the Bible\n",
    "with open('bible/data/bible_by_theme_preprocessed.json') as f:\n",
    "    fragments = json.load(f)\n",
    "\n",
    "# Loading json in df\n",
    "fragments_df = pd.DataFrame(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion_4o(prompt, model=\"gpt-4o\"):\n",
    "    messages=[\n",
    "       {\"role\": \"system\", \"content\": \"Tú eres un sacerdote de una iglesia católica\"},\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "       ]    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt v2\n",
    "instructions = \"\"\"\n",
    "# Rol #\n",
    "Tu eres el GPT: Catholic Bible Guide by Fr. Abraham Mutholath.\n",
    "Tu rol será el de un sacerdote de una iglesia Católica. Se te dará distintos fragmentos de la Biblia. Tu tarea será leer los fragmentos y realizar las tareas que se detallen en la siguiente sección.\n",
    "# Fin Rol #\n",
    "\n",
    "# Tarea #\n",
    "explicacion: Explica brevemente el significado espiritual del pasaje bíblico. Relaciona el pasaje con una situación específica en la vida diaria moderna. Incluye detalles que reflejen preocupaciones o desafíos contemporáneos, como trabajo, relaciones, salud, finanzas, etc. Explica como la enseñanza del pasaje puede aplicarse o brindar consuelo en la situación moderna descrita, conectando explícitamente las enseñanzas bíblicas con los desafíos actuales.\n",
    "# fin Tareas #\n",
    "\n",
    "# Estructura input #\n",
    "id_libro|fragmento\n",
    "# Fin estructura input #\n",
    "\n",
    "# Estructura Output #\n",
    "El output debe ser un texto plano separado por | sin \"header\" ni \"footer\"\n",
    "id_libro|explicacion\n",
    "# Fin Estructura Output #\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_response = []\n",
    "\n",
    "for _, verse in fragments_df.iterrows():\n",
    "    input_to_interpret = f\"{verse['pasaje']}|{verse['texto']}\"\n",
    "    prompt = f\"\"\"\n",
    "                {instructions}\n",
    "\n",
    "                # Input # \n",
    "                {input_to_interpret}\n",
    "                # Fin Input #\n",
    "                \"\"\"\n",
    "    response_4o = get_completion_4o(prompt)\n",
    "    list_response.append(response_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_purpose = fragments_df['area_vida'].tolist()\n",
    "list_text = fragments_df['texto'].tolist()\n",
    "list_passage = fragments_df['pasaje'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_text(text):\n",
    "    flattened_text = text.replace('\\n', ' ')\n",
    "    flattened_text = ' '.join(flattened_text.split())\n",
    "    return flattened_text\n",
    "\n",
    "list_response2 = [flatten_text(response) for response in list_response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting ChatGPT response into passage, interpretatino and areas\n",
    "list_passage_2 = []\n",
    "list_interpretation = []\n",
    "list_areas = []\n",
    "list_id = []\n",
    "\n",
    "i = 0\n",
    "for item in list_response2:\n",
    "    passage, interpretation = item.split('|')\n",
    "    i=i+1\n",
    "    id = \"vec\"+str(i)\n",
    "    list_id.append(id)\n",
    "    list_passage_2.append(passage)\n",
    "    list_interpretation.append(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating df with the results\n",
    "bible_by_theme_interpreted = pd.DataFrame({\"id\": list_id,\n",
    "                                           \"pasaje\": list_passage,\n",
    "                                           \"texto\": list_text,\n",
    "                                           \"interpretación\": list_interpretation,\n",
    "                                           \"temas\": list_purpose})\n",
    "\n",
    "# Convert DataFrame to a dictionary\n",
    "bible_by_theme_interpreted_json = bible_by_theme_interpreted.to_dict(orient='records')\n",
    "\n",
    "# Save the list as a JSON file\n",
    "with open('bible/data/bible_by_theme_int_v2.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(bible_by_theme_interpreted_json, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catholic Bible Interpretation: v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library and setting working directory\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.os_utils import find_repo_root\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Setting working directory\n",
    "repo_root = find_repo_root()\n",
    "os.chdir(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "with open('bible/data/catholic_bible.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Converting json into df\n",
    "bible_data = pd.DataFrame(data)\n",
    "bible_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_data.drop(columns=['texto'], inplace=True)\n",
    "bible_data.rename(columns={'texto_cat':'texto'}, inplace=True)\n",
    "bible_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import time\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion_4o(prompt, model=\"gpt-4o\"):\n",
    "    messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "       ]    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=1,\n",
    "        top_p=1.0\n",
    "    )\n",
    "    return response\n",
    "    #return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt v3\n",
    "instructions1 = \"\"\"\n",
    "# Rol #\n",
    "Eres un experto en interpretación bíblica con un profundo entendimiento de la vida moderna. Tu tarea es interpretar pasajes de la Biblia de una manera que sea relevante y aplicable a situaciones cotidianas actuales.\n",
    "# Fin Rol #\n",
    "\n",
    "# Tarea #\n",
    "Para cada pasaje bíblico proporcionado:\n",
    "1. Lee cuidadosamente el texto.\n",
    "2. Identifica el mensaje principal o la enseñanza clave.\n",
    "3. Crea una situación moderna que refleje el tema central del pasaje.\n",
    "4. Describe esa situación moderna y explica como el mensaje del pasaje se aplica.\n",
    "- **No incluyas etiquetas como '# Output #' en tu respuesta.**\n",
    "- **No incluyas saltos de línea en tu respuesta.**\n",
    "- **No incluyas etiquetas como \"Situación moderna:\" o \"Explicación:\"**\n",
    "\n",
    "Tu Respuesta debe tener lo siguiente:\n",
    "Crea una situación moderna que refleje el tema central del pasaje. Describe esa situación moderna y explica como el mensaje del pasaje se aplica.\n",
    "# fin Tareas #\n",
    "\n",
    "# Estructura input #\n",
    "id_libro|fragmento\n",
    "# Fin estructura input #\n",
    "\"\"\"\n",
    "\n",
    "instructions2 = \"\"\"\n",
    "# Estructura Output #\n",
    "id_libro|explicacion\n",
    "# Fin Estructura Output #\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the Bible data\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "list_response = []\n",
    "# Lists to calculate the tokens used in the processing\n",
    "list_token_input = []\n",
    "list_token_output = []\n",
    "\n",
    "for _, verse in bible_data.iterrows():\n",
    "    input_to_interpret = f\"{verse['pasaje']}|{verse['texto']}\"\n",
    "    prompt = f\"\"\"\n",
    "                {instructions1}\n",
    "                # Input # \n",
    "                {input_to_interpret}\n",
    "                # Fin Input #\n",
    "                {instructions2}\n",
    "                \"\"\"\n",
    "    response = get_completion_4o(prompt)\n",
    "    response_4o = response.choices[0].message.content\n",
    "    token_input = response.usage.prompt_tokens\n",
    "    token_output = response.usage.completion_tokens\n",
    "    list_response.append(response_4o)\n",
    "    list_token_input.append(token_input)\n",
    "    list_token_output.append(token_output)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to process: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost of the API call\n",
    "sum(list_token_input)*5/1000000 + sum(list_token_output)*15/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaining the output\n",
    "def clean_output(text_list):\n",
    "    cleaned_list = []\n",
    "    for text in text_list:\n",
    "        # Remove leading/trailing whitespace and newline characters\n",
    "        cleaned_text = text.strip()\n",
    "        # Replace multiple spaces with a single space\n",
    "        cleaned_text = ' '.join(cleaned_text.split())\n",
    "        # Append cleaned text to the list\n",
    "        cleaned_list.append(cleaned_text)\n",
    "    return cleaned_list\n",
    "\n",
    "cleaned_output = clean_output(list_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the output into columns\n",
    "def split_into_columns(text_list):\n",
    "    list_passage = []\n",
    "    list_interpretation = []\n",
    "    \n",
    "    for text in text_list:\n",
    "        # Split each text into two parts: the scripture reference and the description\n",
    "        passage, interpretation = text.split('|', 1)\n",
    "        list_passage.append(passage.strip())\n",
    "        list_interpretation.append(interpretation.strip())\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        'pasaje_out': list_passage,\n",
    "        'interpretacion': list_interpretation\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "output = split_into_columns(cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_data['pasaje_out'] = output['pasaje_out']\n",
    "bible_data['interpretacion'] = output['interpretacion']\n",
    "bible_data.drop(columns=['pasaje_out'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to a dictionary\n",
    "bible_data_json = bible_data.to_dict(orient='records')\n",
    "\n",
    "# Save the list as a JSON file\n",
    "with open('bible/data/cat_bible_int_openai.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(bible_data_json, json_file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
